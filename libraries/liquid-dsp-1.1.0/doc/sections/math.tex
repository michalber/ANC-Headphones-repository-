% 
% MODULE : math
%

\newpage
\section{math}
\label{module:math}
The {\tt math} module implements several useful functions for digital
signal processing including transcendental function not necessarily in
the standard C library,
windowing functions,
and polynomial manipulation methods.

\subsection{Transcendental Functions}
\label{module:math:transcendentals}
This section describes the implementation and interface to
transcendental functions not in the C standard library
including a full arrangement of Gamma and Bessel functions.
Table~\ref{tab:math:transcendentals} summarizes the interfaces provided
in \liquid.

% ------------ TABLE: MATH TRANSCENDENTALS  ------------
\begin{table*}
\caption{Summary of Transcendental Math Interfaces}
\label{tab:math:transcendentals}
\centering
{\small
    \begin{tabular*}{0.65\textwidth}{l@{\extracolsep{\fill}}l}
    \toprule
    {\it function} &
    {\it interface}\\\otoprule
    %
    $\ln\Gamma(z)$          & {\tt liquid\_lngammaf(z)} \\
    $   \Gamma(z)$          & {\tt liquid\_gammaf(z)} \\
    $\ln\gamma(z,\alpha)$   & {\tt liquid\_lnlowergammaf(z,alpha)} \\
    $   \gamma(z,\alpha)$   & {\tt liquid\_lowergammaf(z,alpha)} \\
    $\ln\Gamma(z,\alpha)$   & {\tt liquid\_lnuppergammaf(z,alpha)} \\
    $   \Gamma(z,\alpha)$   & {\tt liquid\_uppergammaf(z,alpha)} \\
    $n!$                    & {\tt liquid\_factorialf(n)} \\\midrule
    %
    $\ln I_\nu(z)$          & {\tt liquid\_lnbesselif(nu,z)} \\
    $    I_\nu(z)$          & {\tt liquid\_besselif(nu,z)} \\
    $    I_0  (z)$          & {\tt liquid\_besseli0f(z)} \\
    $    J_\nu(z)$          & {\tt liquid\_besseljf(nu,z)} \\
    $    J_0  (z)$          & {\tt liquid\_besselj0f(z)} \\\midrule
    %
    $Q(z)$                  & {\tt liquid\_Qf(z)} \\
    $Q_M(\alpha,\beta)$     & {\tt liquid\_MarcumQf(M,alpha,beta)} \\
    $Q_1(\alpha,\beta)$     & {\tt liquid\_MarcumQ1f(alpha,beta)} \\\midrule
    %
    $\sinc(z)$              & {\tt liquid\_sincf(z)} \\
    $\lceil\log_2(n)\rceil$ & {\tt liquid\_nextpow2(n)} \\
    ${n \choose k}$         & {\tt liquid\_nchoosek(n,k)} \\\bottomrule
    \end{tabular*}
}
\end{table*}%
% ------------------------


% 
% Gamma
%
\subsubsection{{\tt liquid\_gammaf(z)}, {\tt liquid\_lngammaf(z)}}
\label{module:math:transcendentals:gamma}
\liquid\ computes $\Gamma(z)$ from $\ln\Gamma(z)$
(see below) due to its steep, exponential response to $z$.
The complete Gamma function is defined as
%
\begin{equation}
\label{eqn:math:gamma}
    \Gamma(z) \triangleq \int_0^\infty{t^{z-1}e^{-t}dt}
\end{equation}
%
The upper an lower incomplete Gamma functions are described in
Sections~\ref{module:math:transcendentals:uppergamma} and
         \ref{module:math:transcendentals:lowergamma},
respectively.
%
The natural log of the complete Gamma function is computed by splitting
into discrete piecewise sections:
%
\begin{equation}
\label{eqn:math:lngamma}
    \ln\left[ \Gamma(z) \right] \approx
    \begin{cases}
    % undefined for z < 0
        \text{undefined}
        & z < 0 \\
    % low signal approximation (recursion)
        \ln\Gamma(z+1) - \ln(z)
        & 0 \le z < 10 \\
    % high signal approximation
        \frac{z}{2} \ln\left( \frac{2\pi}{z} \right)
        \left(
            \ln\left(z + \frac{1}{12 z - 0.1/z} \right) - 1
        \right)
        & z \ge 0.6
    \end{cases}
\end{equation}
%
%where $\gamma=0.57721566490153286\ldots$ is the Euler-Mascheroni constant.


% 
% lower gamma
%
\subsubsection{{\tt liquid\_lowergammaf(z,a)},
               {\tt liquid\_lnlowergammaf(z,a)}
               (lower incomplete Gamma)}
\label{module:math:transcendentals:lowergamma}
Like $\Gamma(z)$,
\liquid\ computes the lower incomplete gamma function
$\gamma(z,\alpha)$ from its logarithm $\ln\gamma(z,\alpha)$
due to its steep, exponential response to $z$.
The lower incomplete Gamma function is defined as
%
\begin{equation}
\label{eqn:math:lowergamma}
    \gamma(z,\alpha) \triangleq \int_0^\alpha{ t^{z-1}e^{-t}dt }
\end{equation}
%
\liquid\ computes the log of lower incomplete Gamma function as
%
\begin{equation}
\label{eqn:math:lnlowergamma}
    \ln\gamma(z,\alpha) =
        z \ln(\alpha) +
        \ln\Gamma(z) -
        \alpha +
        \ln\left[
            \sum_{k=0}^\infty{
                \frac{\alpha^k}{\Gamma(z + k + 1)}
            }
        \right]
\end{equation}
%



% 
% upper gamma
%
\subsubsection{{\tt liquid\_uppergammaf(z,a)},
               {\tt liquid\_lnuppergammaf(z,a)}
               (upper incomplete Gamma)}
\label{module:math:transcendentals:uppergamma}
Like $\Gamma(z)$,
\liquid\ computes the upper incomplete gamma function
$\Gamma(z,\alpha)$ from $\ln\Gamma(z,\alpha)$
due to its steep, exponential response to $z$.
The complete Gamma function is defined as
%
\begin{equation}
\label{eqn:math:uppergamma}
    \Gamma(z,\alpha) \triangleq \int_\alpha^\infty{t^{z-1}e^{-t}dt}
\end{equation}
%
By definition the sum of the lower and upper incomplete gamma functions
is the complete Gamma function:
$\Gamma(z) = \gamma(z,\alpha) + \Gamma(z,\alpha)$.
As such,
\liquid\ computes the upper incomplete Gamma function as
%
\begin{equation}
\label{eqn:math:lnuppergamma}
    \Gamma(z,\alpha) = \Gamma(z) - \gamma(z,\alpha)
\end{equation}
%



% 
% factorial
%
\subsubsection{{\tt liquid\_factorialf(n)}}
\label{module:math:transcendentals:factorial}
\liquid\ computes $n!=n\cdot(n-1)\cdot(n-2)\cdots3\cdot2\cdot1$
iteratively for small values of $n$, and with the Gamma function for
larger values.
Specifically, $n! = \Gamma(n+1)$.

%
\subsubsection{{\tt liquid\_nchoosek()}}
\label{module:math:transcendentals:nchoosek}
\liquid\ computes binomial coefficients using the
{\tt liquid\_nchoosek()} method:
%
\begin{equation}
\label{eqn:math:nchoosek}
    {n \choose k} = \frac{n!}{(n-k)!k!}
\end{equation}
%
Because the arguments can explode for relatively large values of $n$ and
$k$, \liquid\ uses the following approximation under certain conditions:
\[
    {n \choose k} \approx 
        \exp\Bigl\{
            \ln\Gamma(n+1) -
            \ln\Gamma(n-k+1) -
            \ln\Gamma(k+1)
        \Bigr\}
\]

\subsubsection{{\tt liquid\_nextpow2()}}
\label{module:math:transcendentals:nextpow2}
    computes $\lceil \log_2(x) \rceil$




% 
% sinc
%
\subsubsection{{\tt liquid\_sinc(z)}}
\label{module:math:transcendentals:sinc}
The $\sinc$ function is defined as
%
\begin{equation}
\label{eqn:math:sinc}
    \sinc(z) = \frac{\sin(\pi z)}{\pi z}
\end{equation}
%
Simply evaluating the above equation with finite precision for $z$ results in
a discontinuity for small $z$, and is approximated by expanding the first few
terms of the series
%
\begin{equation}
\label{eqn:math:sinc_expanded}
    \sinc(z) = \prod_{k=1}^{\infty}{ \cos\left( 2^{-k} \pi z \right) }
\end{equation}

%
% Bessel-I
%
\subsubsection{{\tt liquid\_lnbesselif()},
               {\tt liquid\_besselif()},
               {\tt liquid\_besseli0f()}}
\label{module:math:transcendentals:besseli}
$I_\nu(z)$ is the modified Bessel function of the first kind and is
particularly useful for filter design.
An iterative method for computing $I_\nu$ comes from Gross(1995),
%\cite{Gross:1995}
\begin{equation}
\label{eqn:math:besseli}
    I_\nu(z) =
        \left(\frac{z}{2}\right)^\nu
        \sum_{k=0}^{\infty}{\frac{\left(\frac{1}{4}z^2\right)^k}{k!\Gamma(k+\nu+1)}}
\end{equation}
%
Due to its steep response to $z$ it is often useful to compute
$I_\nu(z)$ by first computing $\ln I_\nu(z)$ as
%
\begin{eqnarray*}
\label{eqn:math:lnbesseli}
    \ln I_\nu(z) & = &
        \nu\ln(z/2) + \ln\left[
            \sum_{k=0}^\infty{
                \frac{
                    \left(\frac{1}{4}z^2\right)^k
                }{
                    k! \Gamma(\nu + k + 1)
                }
            }
        \right] \\
        & = &
        \nu\ln(z/2) + \ln\left[
            \sum_{k=0}^\infty{ \exp\Bigl\{
                2 k \ln(z/2) - \ln\Gamma(k+1) - \ln\Gamma(\nu+k+1)
            \Bigr\} }
        \right] \\
\end{eqnarray*}
%
For $\nu=0$ a good approximation can be derived by
using piecewise polynomials,
%
\begin{equation}
\label{eqn:math:besseli0_approx}
    \ln\Bigl[\ln\left(I_0(z)\right)\Bigr] \approx
    c_0 + c_1 t + c_2 t ^2 + c_3 t^3
\end{equation}
%
where $t=\ln(z)$ and
%
\[
    \left\{c_0,c_1,c_2,c_3\right\} =
    \begin{cases}
    \left\{\text{-1.52624, 1.9597, -9.4287e-03, -7.0471e-04}\right\} & t < 0.5 \\
    \left\{\text{-1.5531, 1.8936, -0.07972, -0.01333}\right\} & 0.5 \le t < 2.3 \\
    \left\{\text{-1.2958, 1.7693, -0.1175, 0.006341}\right\} & \text{else}.
    \end{cases}
\]
This is a particularly useful approximation for the Kaiser window in
fixed-point math where $w[n]$ is computed as the ratio of two large numbers.



%
% Bessel-J
%
\subsubsection{{\tt liquid\_lnbesseljf()},
               {\tt liquid\_besselj0f()}}
\label{module:math:transcendentals:besselj}
$J_\nu(z)$ is the Bessel function of the first kind and is found in
Doppler filter design.
\liquid\ computes $J_\nu(z)$ using the series expansion
%
\begin{equation}
\label{eqn:math:besselj}
    J_\nu(z) =
        \sum_{k=0}^\infty{
            \frac{
                (-1)^k
            }{
                2^{2k+|v|} k! \left(|v|+k\right)!
            }
            z^{2k+|v|}
        }
\end{equation}

%
% Bessel-J
%
\subsubsection{{\tt liquid\_Qf()},
               {\tt liquid\_MarcumQf()},
               {\tt liquid\_MarcumQ1f()}}
\label{module:math:transcendentals:Q}
The $Q$-function is commonly used in signal processing and is defined as
%
\begin{eqnarray*}
    Q(z) &=& \frac{1}{2}\left(1 - \erf(z/\sqrt{2})\right) \\
         &=& \frac{1}{\sqrt{2\pi}} \int_{z}^{\infty} { \exp\left\{-u^2/2 \right\} du }
\end{eqnarray*}
%
Similarly Marcum's $Q$-function is defined as the following, with an
appropriate expansion:
%
\begin{eqnarray*}
    Q_M(\alpha,\beta) & = &
        \int_{\beta}^{\infty}{
            u\left(\frac{u}{\alpha}\right)^{M-1}
            \exp\left\{ -\frac{u^2 + \alpha^2}{2}\right\}
            I_{M-1}(\alpha u)
            du
        }\\
        & = &
        \exp\left\{-\frac{\alpha^2 + \beta^2}{2}\right\}
        \sum_{k=1-M}^{\infty}{
            \left(\frac{\alpha}{\beta}\right)^k
            I_k(\alpha\beta)
        }
\end{eqnarray*}
%
where $I_\nu$ is the modified Bessel function of the first kind
(see \S\ref{module:math:transcendentals:besseli}).
\liquid\ implements $Q_M(\alpha,\beta)$ with the function
{\tt liquid\_MarcumQf(M,a,b)} using the approximation
\cite[(25)]{Helstrom:1992}
\[
    Q_M(\alpha,\beta) \approx \textup{erfc}(u),
        \,\,\, u=\frac{\beta-\alpha-M}{\sigma^2},
        \,\,\, \sigma = M + 2\alpha
\]
%
which works over a reasonable range of $M$, $\alpha$, and $\beta$.
%
The special case for $M=1$ is implemented in \liquid\ using the function
{\tt liquid\_MarcumQ1f(M,a,b)} using the expansion \cite{Helstrom:1960},
%
\[
    Q_1(\alpha,\beta) =
        \exp\left\{-\frac{\alpha^2 + \beta^2}{2}\right\}
        \sum_{k=0}^{\infty}{
            \left(\frac{\alpha}{\beta}\right)^k
            I_k(\alpha\beta)
        }
\]
%
which converges quickly with a few iterations.


%
% Complex Trig
%
\subsection{Complex Trigonometry}
\label{module:math:complex}
This section describes the implementation and interface to
complex trigonometric functions not in the C standard library.
Table~\ref{tab:math:transcendentals} summarizes the interfaces provided
in \liquid.

% ------------ TABLE: MATH COMPLEX TRIG  ------------
\begin{table*}
\caption{Summary of Complex Trigonometric Math Interfaces}
\label{tab:math:complex}
\centering
{\small
    \begin{tabular*}{0.65\textwidth}{l@{\extracolsep{\fill}}l}
    \toprule
    {\it function} &
    {\it interface}\\\otoprule
    %
    $\sqrt{z}$              & {\tt liquid\_csqrtf(z)} \\
    $e^{z}$                 & {\tt liquid\_cexpf(z)} \\
    $\ln(z)$                & {\tt liquid\_clogf(z)} \\\midrule
    $\sin^{-1}(z)$          & {\tt liquid\_casinf(z)} \\
    $\cos^{-1}(z)$          & {\tt liquid\_cacosf(z)} \\
    $\tan^{-1}(z)$          & {\tt liquid\_catanf(z)} \\\bottomrule
    \end{tabular*}
}
\end{table*}%
% ------------------------



\subsubsection{{\tt liquid\_csqrtf()}}
\label{module:math:complex:csqrtf}
The function {\tt liquid\_csqrtf(z)}
computes the complex square root of a number
%
\begin{equation}
\label{eqn:math:csqrtf}
    \sqrt{z} = \sqrt{\frac{r+a}{2}} +
               j\text{sgn}\bigl(\Im\{z\}\bigr)
               \sqrt{\frac{r-a}{2}}
\end{equation}
%
where $r=|z|$, $a=\Re\{z\}$, and $\text{sgn}(t)=t/|t|$.

\subsubsection{{\tt liquid\_cexpf()}}
\label{module:math:complex:cexpf}
The function {\tt liquid\_cexpf(z)}
computes the complex exponential of a number
%
\begin{equation}
\label{eqn:math:cexpf}
    e^{z} = \exp\bigl\{a\bigr\}
            \bigl(
                \cos(b) + j\sin(b)
            \bigr)
\end{equation}
%
where $a=\Re\{z\}$ and $b=\Im\{z\}$.


\subsubsection{{\tt liquid\_clogf()}}
\label{module:math:complex:clogf}
The function {\tt liquid\_clogf(z)}
computes the complex natural logarithm of a number.
%
\begin{equation}
\label{eqn:math:clogf}
    \log(z) =   \log(|z|) + j\arg(z)
\end{equation}
%


\subsubsection{{\tt liquid\_cacosf()}}
\label{module:math:complex:cacosf}
The function {\tt liquid\_cacosf(z)}
computes the complex $\arccos$ of a number
%
\begin{equation}
\label{eqn:math:cacosf}
    \arccos(z) =
        \begin{cases}
        -j \log\bigl( z + \sqrt{z^2 - 1} \bigr) &
            \text{sgn}\bigl(\Re\{z\}\bigr) =
            \text{sgn}\bigl(\Im\{z\}\bigr) \\
        -j \log\bigl( z - \sqrt{z^2 - 1} \bigr) & \text{otherwise}
        \end{cases}
\end{equation}
%


\subsubsection{{\tt liquid\_casinf()}}
\label{module:math:complex:casinf}
The function {\tt liquid\_casinf(z)}
computes the complex $\arcsin$ of a number
%
\begin{equation}
\label{eqn:math:casinf}
    \arcsin(z) = \frac{\pi}{2} - \arccos(z)
\end{equation}
%



\subsubsection{{\tt liquid\_catanf()}}
\label{module:math:complex:catanf}
The function {\tt liquid\_catanf(z)}
computes the complex $\arctan$ of a number
%
\begin{equation}
\label{eqn:math:catanf}
    \arctan(z) =
        \frac{j}{2}
        \log\left( \frac{1-jz}{1+jz} \right)
\end{equation}
%


% 
% windowing
%
\subsection{Windowing functions}
\label{module:math:window}
This section describes the various windowing functions in the {\tt math}
module.
These windowing functions are useful for spectral approximation as they
are compact in both the time and frequency domains.

\subsubsection{{\tt hamming()}, (Hamming window)}
\label{module:math:window:hamming}
The function {\tt hamming(n,N)} computes the $n^{th}$ of $N$ indices of
the Hamming window:
%
\begin{equation}
\label{eqn:math:window:hamming}
    w(n) = 0.53836 - 0.46164 \cos\left( 2 \pi n / (N-1) \right)
\end{equation}
%
% FIGURE: Hamming window
% 
\mbox{
  \centering
  \includegraphics[trim = 14mm 0mm 14mm 0mm, clip, width=8cm]{figures.gen/math_window_hamming_time}
  \quad
  \includegraphics[trim = 14mm 0mm 14mm 0mm, clip, width=8cm]{figures.gen/math_window_hamming_freq}
}

\subsubsection{{\tt hann()}, (Hann window)}
\label{module:math:window:hann}
The function {\tt hann(n,N)} computes the $n^{th}$ of $N$ indices of
the Hann window:
%
\begin{equation}
\label{eqn:math:window:hann}
    w(n) = 0.5 - 0.5 \cos\left( 2 \pi n / (N-1) \right)
\end{equation}
%
% FIGURE: Hann window
% 
\mbox{
  \centering
  \includegraphics[trim = 14mm 0mm 14mm 0mm, clip, width=8cm]{figures.gen/math_window_hann_time}
  \quad
  \includegraphics[trim = 14mm 0mm 14mm 0mm, clip, width=8cm]{figures.gen/math_window_hann_freq}
}
%


\subsubsection{{\tt blackmanharris()}, (Blackman-harris window)}
\label{module:math:window:blackmanharris}
The function {\tt blackmanharris(n,N)} computes the $n^{th}$ of $N$
indices of the Blackman-harris window:
%
\begin{equation}
\label{eqn:math:window:blackmanharris}
    w(n) = \sum_{k=0}^{3} { a_k \cos\left( 2 \pi k n / (N-1)\right) }
\end{equation}
%
where
$a_0 =  0.35875$,
$a_1 = -0.48829$,
$a_2 =  0.14128$, and
$a_3 = -0.01168$.

%
% FIGURE: Blackman-harris window
% 
\mbox{
  \centering
  \includegraphics[trim = 14mm 0mm 14mm 0mm, clip, width=8cm]{figures.gen/math_window_blackmanharris_time}
  \quad
  \includegraphics[trim = 14mm 0mm 14mm 0mm, clip, width=8cm]{figures.gen/math_window_blackmanharris_freq}
}
%

\subsubsection{{\tt kaiser()}, (Kaiser-Bessel window)}
\label{module:math:window:kaiser}
The function {\tt kaiser(n,N,dt,beta)} computes the $n^{th}$ of $N$
indices of the Kaiser-$\beta$ window with a shape parameter $\beta$:
%
\begin{equation}
\label{eqn:math:window:kaiser}
    w(n,\beta) = \frac{
        I_0\left(\pi\beta\sqrt{1-\left(\frac{n}{N/2}\right)^2}\right)
    }{
        I_0\left(\pi\beta\right)
    }
\end{equation}
%
where $I_\nu(z)$ is the modified Bessel function of the first kind of
order $\nu$, and $\beta$ is a parameter controlling the width of the
window and its stop-band attenuation.
In \liquid, $I_0(z)$ is computed using {\tt liquid\_besseli0f()}
(see \S\ref{module:math:transcendentals}).
A fractional sample offset $\Delta t$ can be introduced by substituting
$\frac{n}{N/2}$ with
$\frac{n}{N/2} + \Delta t$ in (\ref{eqn:math:window:kaiser}).

%
% FIGURE: Kaiser window
% 
\mbox{
  \centering
  \includegraphics[trim = 14mm 0mm 14mm 0mm, clip, width=8cm]{figures.gen/math_window_kaiser_time}
  \quad
  \includegraphics[trim = 14mm 0mm 14mm 0mm, clip, width=8cm]{figures.gen/math_window_kaiser_freq}
}
%

\subsubsection{{\tt liquid\_kbd\_window()}, (Kaiser-Bessel derived window)}
\label{module:math:window:kbd}
The function {\tt liquid\_kbd\_window(n,beta,*w)}
computes the $n$-point Kaiser-Bessel derived window with a shape
parameter $\beta$ storing the result in the $n$-point array {\tt w}.
The length of the window {\em must} be even.

%
% FIGURE: KBD window
% 
\mbox{
  \centering
  \includegraphics[trim = 14mm 0mm 14mm 0mm, clip, width=8cm]{figures.gen/math_window_kbd_time}
  \quad
  \includegraphics[trim = 14mm 0mm 14mm 0mm, clip, width=8cm]{figures.gen/math_window_kbd_freq}
}
%


% 
% POLYNOMIALS
%
\subsection{Polynomials}
\label{module:math:poly}
A number of \liquid\ modules require polynomial manipulations, particularly
those involving filter design where transfer functions are represented as the
explicit ratio of polynomials in $z^{-1}$.
This sub-module is not intended to be complete, but rather is required for
the proper functionality of other modules.
Like matrices, polynomials in \liquid\ do not use a particular data type, but
are stored as memory arrays.
%
\begin{equation}
\label{eqn:math:poly:representation}
    P_n(x) = \sum_{k=0}^{n}{c_k x^k}
           = c_0 + c_1 x + c_2 x^2 + \cdots + c_n x^n
\end{equation}
%
An $n^{th}$-order polynomial has $n+1$ coefficients ordered in memory in
increasing degree.%
\footnote{Note that this convention is reversed from that used in octave
\cite{octave:web}.}
For example, a $2^{nd}$-order polynomial $0.1 -2.4x + 1.3x^2$ stored in
an array {\tt float c[]} has
{\tt c[0]=0.1},
{\tt c[1]=-2.4}, and
{\tt c[2]=1.3}.

Notice that all routines for the type {\it float} are prefaced with
{\tt polyf}.
This follows the naming convention of the standard C library routines
which append an {\tt f} to the end of methods operating on
floating-point precision types.
Similar matrix interfaces exist in \liquid\ for
{\it double} ({\tt poly}),
{\it double complex} ({\tt polyc}), and
{\it float complex} ({\tt polycf}).


\subsubsection{{\tt polyf\_val()}}
\label{module:math:poly:polyf_val}
The {\tt polyf\_val(*p,k,x)} method evaluates the polynomial $P_n(x)$ at
$x_0$ where the {\tt k} coefficients are stored in the input array
{\tt p}.
Here is a brief example which evaluates $P_2(x) = 0.2 + 1.0x + 0.4x^2$
at $x=1.3$:
%
\begin{Verbatim}[fontsize=\small]
    float p[3] = {0.2f, 1.0f, 0.4f};
    float x = 1.3f;
    float y = polyf_val(p,3,x);
    >>> y = 2.17599988
\end{Verbatim}

\subsubsection{{\tt polyf\_fit()}}
\label{module:math:poly:polyf_fit}
The {\tt polyf\_fit(*x,*y,n,*p,k)} method
fits data to a polynomial of order $k-1$ from $n$ samples using the
least-squares method on the input data vectors
$\vec{x}=[x_0,x_1,\cdots,x_{n-1}]^T$ and 
$\vec{y}=[y_0,y_1,\cdots,y_{n-1}]^T$.
Internally \liquid\
uses matrix algebra to solve the system of equations
%
\begin{equation}
\label{eqn:math:poly:syseq}
    \vec{p} = \left(\vec{X}^T\vec{X}\right)^{-1}\vec{X}^T\vec{y}
\end{equation}
%
where
%
\begin{equation}
\label{eqn:math:poly:polyfit}
    \vec{X} = 
    \begin{bmatrix}
        1   & x_0       & x_0^2     & \cdots    & x_0^{k}     \\
        1   & x_1       & x_1^2     & \cdots    & x_1^{k}     \\
        \\
        1   & x_{n-1}   & x_{n-1}^2 & \cdots    & x_{n-1}^{k}
    \end{bmatrix}
\end{equation}
%
For example this script fits the 4 data samples to a linear
(first-order, two coefficients) polynomial:
%
\begin{Verbatim}[fontsize=\small]
    float x[4] = {0.0f,  1.0f,  2.0f,  3.0f};
    float y[4] = {0.85f, 3.07f, 5.07f, 7.16f};
    float p[2];
    polyf_fit(x,y,4,p,2);
    >>> p = {  0.89800072,   2.09299946}
\end{Verbatim}


\subsubsection{{\tt polyf\_fit\_lagrange()}}
\label{module:math:poly:polyf_fit_lagrange}
The {\tt polyf\_fit\_lagrange(*x,*y,n,*p)} method fit a dataset
of $n$ sample points to exact polynomial of order $n-1$ using
Lagrange interpolation.
Given input vectors
$\vec{x}=[x_0,x_1,\cdots,x_{n-1}]^T$ and 
$\vec{y}=[y_0,y_1,\cdots,y_{n-1}]^T$, the interpolating polynomial is
%
\begin{equation}
\label{eqn:math:poly:polyfit_lagrange}
    P_{n-1}(x) =
        \sum_{j=0}^{n-1} {
            \left[
            y_j
            \prod_{{k=0}\atop{k \ne j}}^{n-1} {
                \frac{x-x_k}{x_j-x_k}
            }
            \right]
        }
\end{equation}
%
For example this script fits the 4 data samples to a cubic
(third-order, four coefficients) polynomial:
%
\begin{Verbatim}[fontsize=\small]
    float x[4] = {0.0f,  1.0f,  2.0f,  3.0f};
    float y[4] = {0.85f, 3.07f, 5.07f, 7.16f};
    float p[4];
    polyf_fit_lagrange(x,y,4,p);
    >>> p = {  0.85000002,   2.43333268,  -0.26499939,   0.05166650}
\end{Verbatim}
%
Notice that {\tt polyf\_fit\_lagrange(x,y,n,p)}
is mathematically equivalent to {\tt polyf\_fit(x,y,n,p,n)},
but is computed in fewer steps.
%
See also {\tt polyf\_expandroots}.

\subsubsection{{\tt polyf\_interp\_lagrange()}}
\label{module:math:poly:polyf_interp_lagrange}
The {\tt polyf\_interp\_lagrange(*x,*y,n,x0)} method
uses Lagrange polynomials to find the interpolant
$(\dot{x},\dot{y})$ from a set of $n$ pairs
$\vec{x}=[x_0,x_1,\cdots,x_{n-1}]^T$ and 
$\vec{y}=[y_0,y_1,\cdots,y_{n-1}]^T$.
%
\begin{equation}
\label{eqn:math:poly:polyinterp_lagrange}
    \dot{y} =
        \sum_{j=0}^{n-1} {
            \left[
            y_j
            \prod_{{k=0}\atop{k \ne j}}^{n-1} {
                \frac{\dot{x}-x_k}{x_j-x_k}
            }
            \right]
        }
\end{equation}
%
For example this script interpolates between the 4 data points
%
\begin{Verbatim}[fontsize=\small]
    float x[4] = {0.0f,  1.0f,  2.0f,  3.0f};
    float y[4] = {0.85f, 3.07f, 5.07f, 7.16f};
    float x0 = 0.5f;
    float y0 = polyf_interp_lagrange(x,y,4,x0);
    >>> y0 =   2.00687504
\end{Verbatim}
%
See also {\tt polyf\_fit\_lagrange()}.

\subsubsection{{\tt polyf\_fit\_lagrange\_barycentric()}}
\label{module:math:poly:polyf_fit_lagrange_barycentric}
The {\tt polyf\_fit\_lagrange\_barycentric(*x,n,*w)} method
computes the barycentric weights $\vec{w}$ of $\vec{x}$ via
%
\begin{equation}
\label{eqn:math:poly:polyfit_lagrange_barycentric}
    w_j =   \frac{1}{
                \prod_{k \ne j}{\left(x_j - x_k\right)}
            }
\end{equation}
%
which can be used to compute the interpolant $(\dot{x},\dot{y})$
with fewer computations.
%
\begin{Verbatim}[fontsize=\small]
    float x[4] = {0.0f,  1.0f,  2.0f,  3.0f};
    float w[4];
    polyf_fit_lagrange_barycentric(x,4,w);
    >>> w = {  1.00000000,  -3.00000000,   3.00000000,  -1.00000000}
\end{Verbatim}
%
\begin{figure}
\centering
\begin{minipage}{0.48\textwidth}
  \includegraphics[trim = 19mm 0mm 19mm 0mm, clip, width=\textwidth]{figures.gen/math_polyfit_lagrange}
\end{minipage}
%
\begin{minipage}{0.48\textwidth}
  %{\scriptsize
  {\footnotesize
  \begin{tabular*}{\textwidth}{l@{\extracolsep{\fill}}rlrlr}
    \input{latex.gen/math_polyfit_lagrange}
  \end{tabular*}
  }
\end{minipage}
\caption{{\tt polyf\_fit\_lagrange\_barycentric} example}
\label{fig:module:polyfit_lagrange}
\end{figure}
%
% ------------------------


\subsubsection{{\tt polyf\_val\_lagrange\_barycentric()}}
\label{module:math:poly:polyf_val_lagrange_barycentric}
The {\tt polyf\_val\_lagrange\_barycentric(*x,*y,*w,x0,n)} method
computes the interpolant $(\dot{x},\dot{y})$ given the barycentric
weights $\vec{w}$ (defined above) as
%
\begin{equation}
\label{eqn:math:poly:polyval_lagrange_barycentric}
    \dot{y} =   \frac{
                    \sum\limits_{j=0}^{k-1}{ w_j y_j /(\dot{x}-x_j) }
                } {
                    \sum\limits_{j=0}^{k-1}{     w_j /(\dot{x}-x_j) }
                }
\end{equation}
%
This is the preferred method for computing Lagrange interpolating polynomials,
particularly if $\vec{x}$ is unchanging.
The function returns $\dot{y}$ if $\dot{x}$ is equal to any $x_j$.
%
\begin{Verbatim}[fontsize=\small]
    float x[4] = {0.0f,  1.0f,  2.0f,  3.0f};
    float y[4] = {0.85f, 3.07f, 5.07f, 7.16f};
    float w[4]; 
    polyf_fit_lagrange_barycentric(x,4,w);
    float x0 = 0.5f;
    float y0 = polyf_val_lagrange_barycentric(x,y,w,x0,4);
    >>> y0 =   2.00687504
\end{Verbatim}
%
Lagrange polynomials of the barycentric form are used heavily in
\liquid's implementation of the Parks-McClellan algorithm
({\tt firdespm}) for filter design
(see \S\ref{module:filter:firdespm}).

\subsubsection{{\tt polyf\_expandbinomial()}}
\label{module:math:poly:polyf_expandbinomial}
The {\tt polyf\_expandbinomial(n,*p)} method
expands the a polynomial as a binomial series
%
\begin{equation}
\label{eqn:math:poly:expandbinomial}
    P_n(x) = (x+1)^n = \sum_{k=0}^{n}{ {n \choose k} x^k}
\end{equation}
%
For example the following script will compute
$P_3(x) = (1+x)^3$:
%
\begin{Verbatim}[fontsize=\small]
    float p[4];
    polyf_expandbinomial(3,p);
    >>> p = {  1.00000000,   3.00000000,   3.00000000,   1.00000000}
\end{Verbatim}
%

\subsubsection{{\tt polyf\_expandbinomial\_pm()}}
\label{module:math:poly:polyf_expandbinomial_pm}
Expands the a polynomial as an alternating binomial series
%
\begin{equation}
\label{eqn:math:poly:expandbinomial_pm}
    P_n(x) = (x+1)^m (x-1)^{n-m}
           = \left\{ \sum_{k=0}^{m}  { {n \choose k}    x^k} \right\}
             \left\{ \sum_{k=0}^{n-m}{ {n \choose k} (-x)^k} \right\}
\end{equation}
%
For example the following script will compute
$P_3(x) = (1+x)^2(1-x)$:
%
\begin{Verbatim}[fontsize=\small]
    float p[4];
    polyf_expandbinomial_pm(2,1,p);
    >>> p = {  1.00000000,   1.00000000,  -1.00000000,  -1.00000000}
\end{Verbatim}
%

\subsubsection{{\tt polyf\_expandroots()}}
\label{module:math:poly:polyf_expandroots}
The {\tt polyf\_expandroots(*r,n,*p)} method
expands the a polynomial based on its roots
%
\begin{equation}
\label{eqn:math:poly:expandroots}
    P_n(x) = \prod_{k=0}^{n-1}{(x - r_k)}
\end{equation}
%
where $r_k$ are the roots of $P_n(x)$.
For example, this script will expand the polynomial
$P_3(x) = (x-1)(x+2)(x-3)$ which has roots
$\{1,-2,3\}$:
%
\begin{Verbatim}[fontsize=\small]
    float roots[3] = {1.0f, -2.0f, 3.0f};
    float p[4];
    polyf_expandroots(roots,3,p);
    >>> p = {  6.00000000,  -5.00000000,  -2.00000000,   1.00000000}
\end{Verbatim}
%

\subsubsection{{\tt polyf\_expandroots2()}}
\label{module:math:poly:polyf_expandroots2}
The {\tt polyf\_expandroots2(*a,*b,n,*p)} method
expands the a polynomial as
%
\begin{equation}
\label{eqn:math:poly:expandroots2}
    P_n(x) = \prod_{k=0}^{n-1}{(b_kx-a_k)}
\end{equation}
%
by first factoring out the $b_k$ terms,
invoking {\tt polyf\_expandroots()}, and
multiplying the result by $\prod_k{b_k}$.
For example, this script will expand the polynomial
$P_3(x) = (2x-1)(-3x+2)(-x-3)$:
%
\begin{Verbatim}[fontsize=\small]
    float b[3] = { 2.0f, -3.0f, -1.0f};
    float a[3] = { 1.0f, -2.0f,  3.0f};
    float p[4];
    polyf_expandroots2(b,a,3,p);
    >>> p = {  6.00000000,  11.00000000, -19.00000000,   6.00000000}
\end{Verbatim}
%


\subsubsection{{\tt polyf\_findroots()}}
\label{module:math:poly:polyf_findroots}
The {\tt polyf\_findroots(*p,n,*r)} method
finds the $n$ roots of the $n^{th}$-order polynomial using Bairstow's
method.
% [TODO : add reference]
For an $n^{th}$-order polynomial $P_n(x)$ given by
%
\begin{equation}
\label{eqn:math:poly:roots}
    P_n(x) = \prod_{k=0}^{n-1}{(x-r_k)}
\end{equation}
%
there exists at least one quadratic polynomial $p_{2}(x)=u + vx + x^2$ which
exactly divides $P_{n}(x)$ and has two roots (possibly complex)
%
\begin{equation}
\label{eqn:math:poly:complex_roots}
    r_0 = \frac{1}{2}\left(-v-\sqrt{v^2-4u}\right), \; \\
    r_1 = \frac{1}{2}\left(-v+\sqrt{v^2-4u}\right)
\end{equation}
%
If indeed the roots $r_0$ and $r_1$ are complex, they are also complex
conjugates.
Bairstow's method uses Newtonian iterations to find a pair $u$ and $v$ which
are both finite and real-valued.
This method has several advantages over other methods
\begin{itemize}
\item iterations operate on real-valued math, even if the roots are complex
\item the algorithm is capable of handling multiple roots (unlike the
      Durand-Kerner method), i.e. $P_{n}(x) = (x-2)(x-2)(x-2)\cdots$
\item the algorithm does not rely on expanding the full polynomial and is
      therefore resilient to machine precision
\end{itemize}
Each iteration of Bairstow's algorithm reduces the original polynomial order
by two, eventually collapsing the polynomial.
The initial choice of $u$ and $v$ determine both algorithm convergence and
speed.

\liquid\ implements Bairstow's method with the {\tt polyf\_findroots()}
function which accepts an $n^{th}$-order polynomial in standard expanded form
and computes its $n$ roots.
The last term of the polynomial (highest order) cannot be zero, otherwise the
algorithm will not converge.
%The roots are sorted by complex pairs according to
%{\tt liquid\_cplxpair()} (see section...)


\subsubsection{{\tt polyf\_mul()}}
\label{module:math:poly:polyf_mul}
The {\tt polyf\_mul(*P,n,*Q,m,*S)} method
multiplies two polynomials $P_n(x)$ and $Q_m(x)$ to produce the
resulting polynomial $S_{n+m-1}(x)$.

%\subsubsection{{\tt polyf\_diff()} {\it not yet implemented}}
%Computes the derivative $\frac{\partial}{\partial x}P_n(x)$ of polynomial
%$P_n(x)$
%\[
%    \frac{\partial}{\partial x}P_n(x) = \sum_{k=1}^{n}{c_{k}x^{k-1}}
%\]

