% 
% MODULE : optim
%

\newpage
\section{optim (optimization)}
\label{module:optim}
The {\em optim} module in \liquid\ implements several non-linear
optimization algorithms including
a gradient descent search,
a quasi-Newton search (experimental:
  see \S\ref{module:experimental:qnsearch})
and an evolutionary algorithm.

\subsection{{\tt gradsearch} (gradient search)}
\label{module:optim:gradsearch}
This module implements a gradient or ``steepest-descent'' search.
Given a function $f$ which operates on a vector
$\vec{x} = [x_0,x_1,\ldots,x_{N-1}]^T$ of $N$ parameters,
the gradient search method seeks to find the optimum $\vec{x}$ which
minimizes $f(\vec{x})$.

\subsubsection{Theory}
The gradient search is an iterative method and adjusts $\vec{x}$ proportional
to the negative of the gradient of $f$ evaluated at the current location.
The vector $\vec{x}$ is adjusted by
\[
    \Delta \vec{x}[n+1] = -\gamma[n] \nabla f(\vec{x}[n])
\]
where $\gamma[n]$ is the step size and
$\nabla f(\vec{x}[n])$ is the gradient of $f$ at $\vec{x}$, at the $n^{th}$
iteration.
The gradient is a vector field which points to the greatest rate of increase,
and is computed at $\vec{x}$ as
\[
    \nabla f(\vec{x}) = \left(
        \frac{\partial f}{\partial x_0},
        \frac{\partial f}{\partial x_1},
        \ldots,
        \frac{\partial f}{\partial x_{N-1}}
    \right)
\]
In most non-linear optimization problems, $\nabla f(\vec{x})$ is not known,
and must be approximated for each value of $\vec{x}[n]$ using the finite element
method.
The partial derivative of the $k^{th}$ component is estimated by computing the
slope of $f$ when $x_k$ is increased by a small amount $\Delta$ while holding
all other elements of $\vec{x}$ constant.
This process is repeated for all elements in $\vec{x}$ to compute the gradient
vector.
Mathematically, the $k^{th}$ component of the gradient is approximated by
\[
    \frac{\partial f(\vec{x})}{\partial x_k} \approx 
    \frac{f(x_0,\ldots,x_k+\Delta,\ldots,x_{N-1}) - f(\vec{x})}{\Delta}
\]
Once $\nabla f(\vec{x}[n])$ is known, $\Delta\vec{x}[n+1]$ is computed and the
optimizing vector is updated via
\[
    \vec{x}[n+1] = \vec{x}[n] + \Delta\vec{x}[n+1]
\]

\subsubsection{Momentum constant}
When $f(\vec{x})$ is flat (i.e. $\nabla f(\vec{x})\approx \vec{0}$),
convergence will be slow.
This effect can be mitigated by permitting the update vector equation to
retain a small portion of the previous step vector.
The updated vector at time $n+1$ is
\[
    \vec{x}[n+1] = \vec{x}[n] + \Delta\vec{x}[n+1] + \alpha\Delta\vec{x}[n]
\]
where $\Delta\vec{x}[0] = \vec{0}$.
The effective update at time $n+1$ is
\[
    \vec{x}[n+1] = 
        %\Delta\vec{x}[n+1] +
        \sum_{k=0}^{n+1}{\alpha^{k}\Delta\vec{x}[n+1-k]}
\]
which is stable only for $0 \le \alpha < 1$.
For flat regions, the gradient vector $\nabla f(\vec{x})$ is approximately a
constant $\Delta\vec{x}$, and $\vec{x}[n]$ therefore becomes a geometric
series converging to $\Delta\vec{x}/(1-\alpha)$.
This accelerates the algorithm across relatively flat regions of $f$.
The momentum constant additionally adds some stability for regions where the
gradient method tends to oscillate, such as steep valleys in $f$.

\subsubsection{Step size adjustment}
In \liquid, the gradient is normalized to unity (orthonormal).
That is $\|\nabla f(\vec{x}[n])\|=1$.
Furthermore, $\gamma$ is slightly reduced each epoch by a multiplier $\mu$
\[
    \gamma[n+1] = \mu \gamma[n]
\]
This helps improve stability and convergence over regions where the algorithm
might oscillate due to steep values of $f$.
%The default value for $\mu$ is 0.99.

\subsubsection{Interface}
Here is a summary of the parameters used in the gradient search algorithm and
their default values:
\begin{itemize}
\item[$\Delta$] : step size in computing the gradient (default $10^{-6}$)
\item[$\gamma$] : step size in updating $\vec{x}[n]$ (default 0.002)
\item[$\alpha$] : momentum constant (default 0.1)
\item[$\mu$]    : iterative $\gamma$ adjustment factor (default 0.99)
\end{itemize}
%
\begin{description}
\item[{\tt gradsearch\_create(*userdata,*v,n,utility,min/max,*props)}]
    creates a gradient search object designed to optimize an $n$-point
    vector $\vec{v}$.
    The user-defined utility function and userdata structures define the
    search, as well as the {\tt min/max} flag which can be either
    {\tt LIQUID\_OPTIM\_MINIMIZE} or
    {\tt LIQUID\_OPTIM\_MAXIMIZE}.
    Finally, the search is parametrized by the {\tt props} structure;
    if set to {\tt NULL} the defaults will be used.
    When run the {\tt gradsearch} object will update the ``optimal''
    value in the input vector $\vec{v}$ specified during
    {\tt create()}.
%\item[{\tt gradsearch\_create\_advanced(*userdata,*v,n,delta,gamma,alpha,mu,utility,min/max)}]
\item[{\tt gradsearch\_destroy(q)}]
    destroys a {\tt gradsearch} object, freeing all internally-allocated
    memory.
\item[{\tt gradsearch\_print(q)}]
    prints the internal state of the gradient search object.
\item[{\tt gradsearch\_reset(q)}]
    resets the internal state of the gradient search object.
\item[{\tt gradsearch\_step(q)}]
    steps through a single iteration of the gradient search.
    The result is stored in the original input vector $\vec{v}$
    specified during the {\tt create()} method.
\item[{\tt gradsearch\_execute(q,n,target\_utility)}]
    runs multiple iterations of the search algorithm,
    stopping after either $n$ iterations or if the target utility is
    met.
\end{description}
%
Here is an example of how the {\tt gradient\_search} is used:
% 
% gradsearch example
\input{listings/gradsearch.example.c.tex}
%
Notice that the utility function is a callback that is completely
defined by the user.
%
\begin{figure}
\centering
  \includegraphics[trim = 8mm 5mm 14mm 8mm, clip, width=13cm]{figures.gen/optim_gradsearch}
  \includegraphics[trim = 3mm 15mm 0mm 15mm, clip, width=14cm]{figures.gen/optim_gradsearch_utility}
\caption{
    {\tt gradsearch} performance for 2-parameter Rosenbrock function
    $f(x,y) = (1-x)^2 + 100(y-x^2)^2$
    with a starting point of $(x_0,y_0)=(-0.2,1.4)$.
    The minimum is located at $(1,1)$.}
\label{fig:module:optim:gradsearch}
\end{figure}
%
Figure~\ref{fig:module:optim:gradsearch} depicts the performance of the
gradient search for the Rosenbrock function, defined as
$f(x,y) = (1-x)^2 + 100(y-x^2)^2$ for input parameters $x$ and $y$.
The Rosenbrock function has a minimum at $(x,y)=(1,1)$;
however the minimum lies in a deep valley which can be difficult to
navigate.
From the figure it is apparent that finding the valley is trivial,
but convergence to the minimum is slow.


\subsection{{\tt gasearch} genetic algorithm search}
\label{module:optim:gasearch}
% talking points
%   * chromosome
%   * evolutionary algorithms (briefly)
%   * interface

The {\tt gasearch} object implements an evolutionary (genetic)
algorithm search in \liquid.
The search uses a binary string of traits called a {\em chromosome}
(see \S\ref{module:optim:gasearch:chromosome}, below)
to represent a potential solution.
A {\em population} of chromosomes is generated and their appropriate
fitnesses are calculated.
With each evolution of the population the best chromosomes are retained
and the worst are discarded; this process is known as {\em selection}.
The population is restored by computing new potential solutions by
splitting traits of the better chromosomes into a new member
({\em crossover}) as well as randomly flipping some of the bits in each
chromosome ({\em mutation}).

\subsubsection{{\tt chromosome}, solution representation}
\label{module:optim:gasearch:chromosome}
The {\tt chromosome} object in \liquid\ realizes a binary string of
traits used in the {\tt gasearch} object.
A chromosome has a fixed number of traits as well as a fixed number of
bits to represent each trait;
however the number of bits representing each trait does not necessarily
need to be the same for the chromosome.
That is to say a chromosome may have a number of traits, each with a
different number of bits representing them;
however once a {\tt chromosome} object is created, the number of bits
representing each trait is not allowed to be changed.

Because of the many ways a chromosome can represent information \liquid\
provides a number of methods for creating and initializing chromosomes.
%
\begin{description}
\item[{\tt chromosome\_create(*b,n)}]
    creates a chromosome with $n$ traits.
    The number of bits per trait are specified in the array $\vec{b}$.
\item[{\tt chromosome\_create\_basic(n,b)}]
    creates a chromosome with $n$ traits and a constant $b$ bits for
    each trait.
\item[{\tt chromosome\_create\_clone(p)}]
    clones a chromosome from another one, including its representation
    of traits, the number of bits per trait, as well as the values of
    the traits themselves.
\item[{\tt chromosome\_destroy(q)}]
    destroys a chromosome object, freeing all internally-allocated
    memory.
\end{description}
%
Furthermore, the value of all the chromosome's traits may be set with
the appropriate {\tt init()} method:
%
\begin{description}
\item[{\tt chromosome\_copy(q)}]
    copies an existing chromosomes' internal traits; all other internal
    parameters must be equal.
\item[{\tt chromosome\_init(q,*v)}]
    initializes a chromosome's discrete trait values to the input array
    of {\tt unsigned int} values $\vec{v}$.
    The trait values are in the range $[0,2^{n_k}-1]$ where $n$
    represents the number of bits in the $k^{th}$ trait.
\item[{\tt chromosome\_initf(q,*v)}]
    initializes a chromosome's continuous trait values to the input
    array of {\tt float} values $\vec{v}$.
    The trait values are in the range $[0,1]$ and are represented by
    floating-point values.
    Because each trait has a discrete number of values (limited bit
    resolution), the value of the trait is quantized to its nearest
    representation.
\item[{\tt chromosome\_init\_random(q)}]
    initializes a chromosome's trait values to a random number.
\end{description}
%
The values of specific traits can be retrieved using the {\tt value()}
methods.
They are useful for evaluating the fitness of the chromosome in the
search algorithm's callback function.
%
\begin{description}
\item[{\tt chromosome\_value(q,k)}]
    returns the value of the $k^{th}$ trait (integer representation).
\item[{\tt chromosome\_valuef(q,k)}]
    returns the value of the $k^{th}$ trait (floating-point representation).
\end{description}
%
Finally the methods for use in the {\tt gasearch} algorithm are
described:
%
\begin{description}
\item[{\tt chromosome\_mutate(q,k)}]
    flips the $k^{th}$ bit of the chromosome.
\item[{\tt chromosome\_crossover(p1,p2,c,k)}]
    copies the first $k$ bits of the first parent $p_1$
    and the remaining bits of the second parent $p_2$
    to the child chromosome $c_2$.
\end{description}
%

\subsubsection{Interface}
\label{module:optim:gasearch:interface}
%
Listed below is a description for the {\tt gasearch} object in
\liquid.
%
\begin{description}
\item[{\tt gasearch\_create(*utility,*userdata,parent,min/max)}]
    creates a {\tt gasearch} object, initialized on the specified
    parent chromosome.
    The user-defined utility function and userdata structures define the
    search, as well as the {\tt min/max} flag which can be either
    {\tt LIQUID\_OPTIM\_MINIMIZE} or
    {\tt LIQUID\_OPTIM\_MAXIMIZE}.
    %When run the {\tt gasearch} object will update the ``optimal''
    %value in the input vector $\vec{v}$ specified during
    %{\tt create()}.
%\item[{\tt gasearch\_create\_advanced()}]
\item[{\tt gasearch\_destroy(q)}]
    destroys a {\tt gasearch} object, freeing all internally-allocated
    memory.
\item[{\tt gasearch\_print(q)}]
    prints the internal state of the {\tt gasearch} object
\item[{\tt gasearch\_set\_mutation\_rate(q,rate)}]
    sets the mutation rate
\item[{\tt gasearch\_set\_population\_size(q,population,selection)}]
    sets both the population size as well as the selection size of the
    evolutionary algorithm
\item[{\tt gasearch\_run(q,n,target\_utility)}]
    runs multiple iterations of the search algorithm,
    stopping after either $n$ iterations or if the target utility is
    met.
\item[{\tt gasearch\_evolve(q)}]
    steps through a single iteration of the search.
\item[{\tt gasearch\_getopt(q,*chromosome,*u)}]
    produces the best chromosome over the coarse of the search
    evolution, as well as its utility.
\end{description}
%

\subsubsection{Example Code}
\label{module:optim:gasearch:example}
An example of the {\tt gasearch} interface is given below:
%
\input{listings/gasearch.example.c.tex}
%
Evolutionary algorithms are well-suited for discrete optimization
problems, particularly where a large number of parameters only hold a
few values.
The classic example is the knapsack problem (constrained, non-linear)
in which the selection of items with different weights and values must
be chosen to maximize the total value without exceeding a prescribed
weight capacity.
An example of using the {\tt gasearch} object in \liquid\ to search
over the solution space of the knapsack problem can be found in the
{\tt examples} directory as
{\tt examples/gasearch\_knapsack\_example.c}.

